{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 社会经济调查的职业和行业自动编码模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T14:38:43.952894Z",
     "start_time": "2019-01-25T14:38:21.646950Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample1 = pd.read_excel(\"行业与职业编码数据(一).xlsx\")\n",
    "sample2 = pd.read_excel(\"行业与职业编码数据(二).xlsx\")\n",
    "code = pd.read_excel(\"行业与职业分类代码表.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T23:58:07.440628Z",
     "start_time": "2019-01-25T23:58:07.407902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        受访者编号   题型                                      题目     访员实地填写的答案  类别  \\\n",
      "0      100013  辅助题                                本期自雇单位名称           不知道   0   \n",
      "1      100013   编码                                您单位主要做什么           不知道  行业   \n",
      "2      100063  辅助题                                本期自雇单位名称            养鸡   0   \n",
      "3      100063   编码                                您单位主要做什么            养鸡  行业   \n",
      "4      100093  辅助题                                  本期单位名称        变压器配件厂   0   \n",
      "5      100093  辅助题                                  本期部门名称            车间   0   \n",
      "6      100093  辅助题                                    本期职业             无   0   \n",
      "7      100093   编码                                您单位主要做什么         变压器配件  行业   \n",
      "8      100093   编码                               您的工作内容是什么            打杂  职业   \n",
      "9      100123  辅助题                                本期自雇单位名称           打毛巾   0   \n",
      "10     100123   编码                                您单位主要做什么           打毛巾  行业   \n",
      "11     100143  辅助题                                  本期单位名称        XX村毛坊厂   0   \n",
      "12     100143  辅助题                                  本期部门名称        毛巾生产包装   0   \n",
      "13     100143  辅助题                                    本期职业            没有   0   \n",
      "14     100143   编码                                您单位主要做什么          制造毛巾  行业   \n",
      "15     100143   编码                               您的工作内容是什么        毛巾打捆包装  职业   \n",
      "16     100153  辅助题                                    本期职业             无   0   \n",
      "17     100153   编码                                您单位主要做什么            建筑  行业   \n",
      "18     100153   编码                               您的工作内容是什么          建筑工人  职业   \n",
      "19     100173  辅助题                                  本期单位名称         XX建筑队   0   \n",
      "20     100173  辅助题                                  本期部门名称           建筑队   0   \n",
      "21     100173  辅助题                                    本期职业             否   0   \n",
      "22     100173   编码                                您单位主要做什么           盖房子  行业   \n",
      "23     100173   编码                               您的工作内容是什么           贴瓷砖  职业   \n",
      "24     100353  辅助题                                本期自雇单位名称          蒙文书店   0   \n",
      "25     100353   编码                                您单位主要做什么         销售蒙文书  行业   \n",
      "26     100543  辅助题                                  本期单位名称       XXX农业大学   0   \n",
      "27     100543  辅助题                                  本期部门名称           理学院   0   \n",
      "28     100543  辅助题                                    本期职业           副教授   0   \n",
      "29     100543   编码                                您单位主要做什么            教育  行业   \n",
      "...       ...  ...                                     ...           ...  ..   \n",
      "65490  316268  辅助题        您有专业/技术职称吗？如果有，您 目前的专业/技术职称是什么？           ~技术员  职业   \n",
      "65491  316268  辅助题                               您是否管理别人？             ~否  职业   \n",
      "65492  316268   编码                                您单位主要做什么  滑润油的生产与调和，销售  行业   \n",
      "65493  316268   编码                               您的工作内容是什么    化验室分析化验，调和  职业   \n",
      "65494  316288  辅助题                         您的受雇单位/雇主属于哪种类型          ~个体户  行业   \n",
      "65495  316288  辅助题       第_1个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）         太阳墩牛场  行业   \n",
      "65496  316288  辅助题       第_2个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）           老牛厂  行业   \n",
      "65497  316288  辅助题                              请问您主要做什么工作       ~简单体力劳动  职业   \n",
      "65498  316288  辅助题                             是否有相关的职业资格？            没有  职业   \n",
      "65499  316288  辅助题                         您在单位里目前的职务是什么？          ~普通职工  职业   \n",
      "65500  316288  辅助题        您有专业/技术职称吗？如果有，您 目前的专业/技术职称是什么？          ~无职称   职业   \n",
      "65501  316288  辅助题                               您是否管理别人？             ~否  职业   \n",
      "65502  316288   编码                                您单位主要做什么        养殖牛、售卖  行业   \n",
      "65503  316288   编码                               您的工作内容是什么          谷物种植  职业   \n",
      "65504  316288   编码                               您的工作内容是什么            喂牛  职业   \n",
      "65505  316298  辅助题                         您的受雇单位/雇主属于哪种类型           ~农户  行业   \n",
      "65506  316298  辅助题       第_1个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）        XX村其他人  行业   \n",
      "65507  316298  辅助题       第_2个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）           XX村  行业   \n",
      "65508  316298  辅助题  第_W4_3_1个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）  赵玉辉家已没有农活需要做  行业   \n",
      "65509  316298  辅助题                              请问您主要做什么工作       ~简单体力劳动  职业   \n",
      "65510  316298  辅助题                             是否有相关的职业资格？          没有职业  职业   \n",
      "65511  316298  辅助题        您有专业/技术职称吗？如果有，您 目前的专业/技术职称是什么？          ~无职称   职业   \n",
      "65512  316298  辅助题                               您是否管理别人？             ~否  职业   \n",
      "65513  316298   编码                               您的工作内容是什么          谷物种植  职业   \n",
      "65514  316298   编码                               您的工作内容是什么         帮人干农活  职业   \n",
      "65515  316308  辅助题                              请问您主要做什么工作       ~简单体力劳动  职业   \n",
      "65516  316308   编码                               您的工作内容是什么          管理果树  职业   \n",
      "65517  316318  辅助题                         您的受雇单位/雇主属于哪种类型          ~个体户  行业   \n",
      "65518  316318  辅助题       第_1个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）          建筑工地  行业   \n",
      "65519  316318  辅助题       第_2个：您的受雇单位或者雇主是什么名称？（请标明详细的单位名称）           建筑部  行业   \n",
      "\n",
      "         编码结果  \n",
      "0           0  \n",
      "1      999999  \n",
      "2           0  \n",
      "3       10300  \n",
      "4           0  \n",
      "5           0  \n",
      "6           0  \n",
      "7       32600  \n",
      "8       62903  \n",
      "9           0  \n",
      "10      30500  \n",
      "11          0  \n",
      "12          0  \n",
      "13          0  \n",
      "14      30500  \n",
      "15      62901  \n",
      "16          0  \n",
      "17      50100  \n",
      "18      62202  \n",
      "19          0  \n",
      "20          0  \n",
      "21          0  \n",
      "22      50100  \n",
      "23      62207  \n",
      "24          0  \n",
      "25      80200  \n",
      "26          0  \n",
      "27          0  \n",
      "28          0  \n",
      "29     160100  \n",
      "...       ...  \n",
      "65490       0  \n",
      "65491       0  \n",
      "65492   31300  \n",
      "65493   20204  \n",
      "65494       0  \n",
      "65495       0  \n",
      "65496       0  \n",
      "65497       0  \n",
      "65498       0  \n",
      "65499       0  \n",
      "65500       0  \n",
      "65501       0  \n",
      "65502   10300  \n",
      "65503   50101  \n",
      "65504   50301  \n",
      "65505       0  \n",
      "65506       0  \n",
      "65507       0  \n",
      "65508       0  \n",
      "65509       0  \n",
      "65510       0  \n",
      "65511       0  \n",
      "65512       0  \n",
      "65513   50101  \n",
      "65514   50101  \n",
      "65515       0  \n",
      "65516   50103  \n",
      "65517       0  \n",
      "65518       0  \n",
      "65519       0  \n",
      "\n",
      "[65520 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T14:38:57.353977Z",
     "start_time": "2019-01-25T14:38:57.332012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     first  second  third               text  \\\n",
      "0        1       0      0           农、林、牧、渔业   \n",
      "1        1       1      0                 农业   \n",
      "2        1       2      0                 林业   \n",
      "3        1       3      0                畜牧业   \n",
      "4        1       4      0                 渔业   \n",
      "5        1       5      0         农、林、牧、渔服务业   \n",
      "6        2       0      0                采矿业   \n",
      "7        2       1      0           煤炭开采和洗选业   \n",
      "8        2       2      0          石油和天然气开采业   \n",
      "9        2       3      0           黑色金属矿采选业   \n",
      "10       2       4      0           有色金属矿采选业   \n",
      "11       2       5      0            非金属矿采选业   \n",
      "12       2       6      0              其他采矿业   \n",
      "13       3       0      0                制造业   \n",
      "14       3       1      0            农副食品加工业   \n",
      "15       3       2      0              食品制造业   \n",
      "16       3       3      0              饮料制造业   \n",
      "17       3       4      0              烟草制品业   \n",
      "18       3       5      0                纺织业   \n",
      "19       3       6      0        纺织服装、鞋、帽制造业   \n",
      "20       3       7      0   皮革、毛皮、羽毛(绒)及其制品业   \n",
      "21       3       8      0  木材加工及木、竹、藤、棕、草制品业   \n",
      "22       3       9      0              家具制造业   \n",
      "23       3      10      0            造纸及纸制品业   \n",
      "24       3      11      0        印刷业和记录媒介的复制   \n",
      "25       3      12      0          文教体育用品制造业   \n",
      "26       3      13      0     石油加工、炼焦及核燃料加工业   \n",
      "27       3      14      0       化学原料及化学制品制造业   \n",
      "28       3      15      0              医药制造业   \n",
      "29       3      16      0            化学纤维制造业   \n",
      "..     ...     ...    ...                ...   \n",
      "86      13       3      0         科技交流和推广服务业   \n",
      "87      13       4      0              地质勘查业   \n",
      "88      14       0      0      水利、环境和公共设施管理业   \n",
      "89      14       1      0              水利管理业   \n",
      "90      14       2      0              环境管理业   \n",
      "91      14       3      0            公共设施管理业   \n",
      "92      15       0      0         居民服务和其他服务业   \n",
      "93      15       1      0              居民服务业   \n",
      "94      15       2      0              其他服务业   \n",
      "95      16       0      0                 教育   \n",
      "96      16       1      0                 教育   \n",
      "97      17       0      0      卫生、社会保障和社会福利业   \n",
      "98      17       1      0                 卫生   \n",
      "99      17       2      0              社会保障业   \n",
      "100     17       3      0              社会福利业   \n",
      "101     18       0      0          文化、体育和娱乐业   \n",
      "102     18       1      0              新闻出版业   \n",
      "103     18       2      0       广播、电视、电影和音像业   \n",
      "104     18       3      0              文化艺术业   \n",
      "105     18       4      0                 体育   \n",
      "106     18       5      0                娱乐业   \n",
      "107     19       0      0          公共管理和社会组织   \n",
      "108     19       1      0            中国共产党机关   \n",
      "109     19       2      0               国家机构   \n",
      "110     19       3      0          人民政协和民主党派   \n",
      "111     19       4      0     群众团体、社会团体和宗教组织   \n",
      "112     19       5      0           基层群众自治组织   \n",
      "113     20       0      0               国际组织   \n",
      "114     20       1      0               国际组织   \n",
      "115     21       0      0                 军队   \n",
      "\n",
      "                                              helptext    code  \n",
      "0                                                  NaN   10000  \n",
      "1    指对各种农作物的种植活动。包括谷物及其他作物的种植，蔬菜、园艺作物的种植，水果、坚果、饮料和...   10100  \n",
      "2                          包括林木的培育和种植、木材和竹材的采运、林产品的采集。   10200  \n",
      "3    指为了获得各种畜禽产品而从事的动物饲养活动。包括牲畜的饲养、猪的饲养、家禽的饲养、狩猎和捕捉...   10300  \n",
      "4                                                  NaN   10400  \n",
      "5      指对农、林、牧、渔业生产活动进行的各种支持性服务活动。但不包括各种科学技术和专业技术服务活动。   10500  \n",
      "6    采矿业指对固体（如煤和矿物）、液体（如原油）或气体（如天然气）等自然产生的矿物的采掘。包括地...   20000  \n",
      "7               指对各种煤炭的开采、洗选、分级等生产活动。不包括煤制品的生产和煤炭勘探活动。   20100  \n",
      "8                       包括天然原油和天然气开采，与石油和天然气开采有关的服务活动。   20200  \n",
      "9                    包括铁矿、锰矿、铬矿等钢铁工业黑色金属辅助原料矿的采矿、选矿活动。   20300  \n",
      "10                   指对常用有色金属矿、贵金属矿，以及稀有稀土金属矿的开采、选矿活动。   20400  \n",
      "11    包括土砂石开采、化学矿采选、采盐、石棉及其他非金属矿（石墨、贵重宝石、金刚石、天然磨料等）采选。   20500  \n",
      "12   指对地热资源、矿泉水资源以及其他未列明的自然资源的开采活动。但不包括利用这些资源建立的热电厂...   20600  \n",
      "13     指经物理变化或化学变化后成为了新的产品，不论是动力机械制造，还是手工制做；也不论产品是批...   30000  \n",
      "14   指直接以农、林、牧 、渔业产品为原料进行的谷物磨制、饲料加工、植物油和制糖加工、屠宰及肉类加...   30100  \n",
      "15   包括焙烤食品制造，糖果、巧克力及蜜饯制造，方便食品制造，液体乳及乳制品制造，罐头制造，调味品...   30200  \n",
      "16                            包括酒精制造、酒的制造、软饮料制造、精制茶加工。   30300  \n",
      "17                                       包括烟叶复烤、卷烟制造等。   30400  \n",
      "18   包括棉、化纤纺织及印染精加工，毛纺织和染整精加工，麻纺织，丝绢纺织及精加工，纺织制成品制造，...   30500  \n",
      "19                                                 NaN   30600  \n",
      "20                                                 NaN   30700  \n",
      "21                                                 NaN   30800  \n",
      "22   指用木材、金属、塑料、竹、藤等材料制作的，具有坐卧、凭倚、储藏、间隔等功能，可用于住宅、旅馆...   30900  \n",
      "23                                                 NaN   31000  \n",
      "24                                                 NaN   31100  \n",
      "25             包括文化用品制造、体育用品制造、乐器制造、玩具制造、 游艺器材及娱乐用品制造。   31200  \n",
      "26                                                 NaN   31300  \n",
      "27   包括基础化学原料制造，肥料制造，农药制造，涂料、油墨、颜料及类似产品制造，合成材料制造（包括...   31400  \n",
      "28                                                 NaN   31500  \n",
      "29                                                 NaN   31600  \n",
      "..                                                 ...     ...  \n",
      "86                                                 NaN  130300  \n",
      "87                指对矿产资源、工程地质、科学研究进行的地质勘查、测试、监测、评估等活动。  130400  \n",
      "88                                                 NaN  140000  \n",
      "89                                                 NaN  140100  \n",
      "90                                                 NaN  140200  \n",
      "91                           包括市政公共设施管理、城市绿化管理、游览景区管理。  140300  \n",
      "92                                                 NaN  150000  \n",
      "93   包括家庭服务、托儿所、洗染服务、理发及美容保健服务、洗浴服务、婚姻服务、殡葬服务、摄影扩印服...  150100  \n",
      "94   包括修理与维护（汽车、摩托车维护与保养、办公设备维修、家用电器修理、其他日用品修理）、 清洁...  150200  \n",
      "95                                                 NaN  160000  \n",
      "96                                                 NaN  160100  \n",
      "97                                                 NaN  170000  \n",
      "98   包括医院、卫生院及社区医疗活动、门诊部医疗活动、计划生育技术服务活动、妇幼保健活动、专科疾病...  170100  \n",
      "99                                                 NaN  170200  \n",
      "100                                                NaN  170300  \n",
      "101                                                NaN  180000  \n",
      "102                                                NaN  180100  \n",
      "103  指对广播、电视、电影、录音、录像内容的制作、编导、主持、播出、放映等活动。不包括广播电视信号...  180200  \n",
      "104  包括文艺创作与表演、艺术表演场馆、图书馆与档案馆、文物及文化保护、博物馆、烈士陵园、纪念馆、...  180300  \n",
      "105            包括体育组织（指专业从事体育比赛、训练、辅导和管理的组织的活动）、体育场馆等。  180400  \n",
      "106  包括室内娱乐活动、游乐园、休闲健身娱乐活动、其他娱乐活动（指各种形式的彩票活动，以及公园、海...  180500  \n",
      "107                                                NaN  190000  \n",
      "108                                                NaN  190100  \n",
      "109                              指宪法规定的国家机构的活动和国家武装力量。  190200  \n",
      "110                                                NaN  190300  \n",
      "111                                                NaN  190400  \n",
      "112     指通过选举产生的社区性组织，该组织为本地区提供一般性管理、调解、治安、优抚、计划生育等服务。  190500  \n",
      "113                                                NaN  200000  \n",
      "114                                                NaN  200100  \n",
      "115                                                NaN  210000  \n",
      "\n",
      "[116 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接口部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T14:39:40.712953Z",
     "start_time": "2019-01-25T14:39:40.709923Z"
    }
   },
   "source": [
    "## 模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T23:41:56.246198Z",
     "start_time": "2019-01-25T23:41:56.228303Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T23:42:01.593996Z",
     "start_time": "2019-01-25T23:42:01.570658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdaptiveAvgPool1d',\n",
       " 'AdaptiveAvgPool2d',\n",
       " 'AdaptiveAvgPool3d',\n",
       " 'AdaptiveMaxPool1d',\n",
       " 'AdaptiveMaxPool2d',\n",
       " 'AdaptiveMaxPool3d',\n",
       " 'AlphaDropout',\n",
       " 'AvgPool1d',\n",
       " 'AvgPool2d',\n",
       " 'AvgPool3d',\n",
       " 'BCELoss',\n",
       " 'BCEWithLogitsLoss',\n",
       " 'BatchNorm1d',\n",
       " 'BatchNorm2d',\n",
       " 'BatchNorm3d',\n",
       " 'Bilinear',\n",
       " 'ConstantPad1d',\n",
       " 'ConstantPad2d',\n",
       " 'ConstantPad3d',\n",
       " 'Container',\n",
       " 'Conv1d',\n",
       " 'Conv2d',\n",
       " 'Conv3d',\n",
       " 'ConvTranspose1d',\n",
       " 'ConvTranspose2d',\n",
       " 'ConvTranspose3d',\n",
       " 'CosineEmbeddingLoss',\n",
       " 'CosineSimilarity',\n",
       " 'CrossEntropyLoss',\n",
       " 'CrossMapLRN2d',\n",
       " 'DataParallel',\n",
       " 'Dropout',\n",
       " 'Dropout2d',\n",
       " 'Dropout3d',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'EmbeddingBag',\n",
       " 'Fold',\n",
       " 'FractionalMaxPool2d',\n",
       " 'GLU',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GroupNorm',\n",
       " 'Hardshrink',\n",
       " 'Hardtanh',\n",
       " 'HingeEmbeddingLoss',\n",
       " 'InstanceNorm1d',\n",
       " 'InstanceNorm2d',\n",
       " 'InstanceNorm3d',\n",
       " 'KLDivLoss',\n",
       " 'L1Loss',\n",
       " 'LPPool1d',\n",
       " 'LPPool2d',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'LayerNorm',\n",
       " 'LeakyReLU',\n",
       " 'Linear',\n",
       " 'LocalResponseNorm',\n",
       " 'LogSigmoid',\n",
       " 'LogSoftmax',\n",
       " 'MSELoss',\n",
       " 'MarginRankingLoss',\n",
       " 'MaxPool1d',\n",
       " 'MaxPool2d',\n",
       " 'MaxPool3d',\n",
       " 'MaxUnpool1d',\n",
       " 'MaxUnpool2d',\n",
       " 'MaxUnpool3d',\n",
       " 'Module',\n",
       " 'ModuleList',\n",
       " 'MultiLabelMarginLoss',\n",
       " 'MultiLabelSoftMarginLoss',\n",
       " 'MultiMarginLoss',\n",
       " 'NLLLoss',\n",
       " 'NLLLoss2d',\n",
       " 'PReLU',\n",
       " 'PairwiseDistance',\n",
       " 'Parameter',\n",
       " 'ParameterList',\n",
       " 'PixelShuffle',\n",
       " 'PoissonNLLLoss',\n",
       " 'RNN',\n",
       " 'RNNBase',\n",
       " 'RNNCell',\n",
       " 'RReLU',\n",
       " 'ReLU',\n",
       " 'ReLU6',\n",
       " 'ReflectionPad1d',\n",
       " 'ReflectionPad2d',\n",
       " 'ReplicationPad1d',\n",
       " 'ReplicationPad2d',\n",
       " 'ReplicationPad3d',\n",
       " 'SELU',\n",
       " 'Sequential',\n",
       " 'Sigmoid',\n",
       " 'SmoothL1Loss',\n",
       " 'SoftMarginLoss',\n",
       " 'Softmax',\n",
       " 'Softmax2d',\n",
       " 'Softmin',\n",
       " 'Softplus',\n",
       " 'Softshrink',\n",
       " 'Softsign',\n",
       " 'Tanh',\n",
       " 'Tanhshrink',\n",
       " 'Threshold',\n",
       " 'TripletMarginLoss',\n",
       " 'Unfold',\n",
       " 'Upsample',\n",
       " 'UpsamplingBilinear2d',\n",
       " 'UpsamplingNearest2d',\n",
       " 'ZeroPad2d',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functions',\n",
       " 'backends',\n",
       " 'functional',\n",
       " 'grad',\n",
       " 'init',\n",
       " 'modules',\n",
       " 'parallel',\n",
       " 'parameter',\n",
       " 'utils']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T23:45:35.594676Z",
     "start_time": "2019-01-25T23:45:35.576159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BatchNorm2d in module torch.nn.modules.batchnorm:\n",
      "\n",
      "class BatchNorm2d(_BatchNorm)\n",
      " |  Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs\n",
      " |  with additional channel dimension) as described in the paper\n",
      " |  `Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
      " |  \n",
      " |  The mean and standard-deviation are calculated per-dimension over\n",
      " |  the mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\n",
      " |  of size `C` (where `C` is the input size).\n",
      " |  \n",
      " |  By default, during training this layer keeps running estimates of its\n",
      " |  computed mean and variance, which are then used for normalization during\n",
      " |  evaluation. The running estimates are kept with a default :attr:`momentum`\n",
      " |  of 0.1.\n",
      " |  \n",
      " |  If :attr:`track_running_stats` is set to ``False``, this layer then does not\n",
      " |  keep running estimates, and batch statistics are instead used during\n",
      " |  evaluation time as well.\n",
      " |  \n",
      " |  .. note::\n",
      " |      This :attr:`momentum` argument is different from one used in optimizer\n",
      " |      classes and the conventional notion of momentum. Mathematically, the\n",
      " |      update rule for running statistics here is\n",
      " |      :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momemtum} \\times x_t`,\n",
      " |      where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n",
      " |      new observed value.\n",
      " |  \n",
      " |  Because the Batch Normalization is done over the `C` dimension, computing statistics\n",
      " |  on `(N, H, W)` slices, it's common terminology to call this Spatial Batch Normalization.\n",
      " |  \n",
      " |  Args:\n",
      " |      num_features: :math:`C` from an expected input of size\n",
      " |          :math:`(N, C, H, W)`\n",
      " |      eps: a value added to the denominator for numerical stability.\n",
      " |          Default: 1e-5\n",
      " |      momentum: the value used for the running_mean and running_var\n",
      " |          computation. Can be set to ``None`` for cumulative moving average\n",
      " |          (i.e. simple average). Default: 0.1\n",
      " |      affine: a boolean value that when set to ``True``, this module has\n",
      " |          learnable affine parameters. Default: ``True``\n",
      " |      track_running_stats: a boolean value that when set to ``True``, this\n",
      " |          module tracks the running mean and variance, and when set to ``False``,\n",
      " |          this module does not track such statistics and always uses batch\n",
      " |          statistics in both training and eval modes. Default: ``True``\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C, H, W)`\n",
      " |      - Output: :math:`(N, C, H, W)` (same shape as input)\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # With Learnable Parameters\n",
      " |      >>> m = nn.BatchNorm2d(100)\n",
      " |      >>> # Without Learnable Parameters\n",
      " |      >>> m = nn.BatchNorm2d(100, affine=False)\n",
      " |      >>> input = torch.randn(20, 100, 35, 45)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:\n",
      " |      https://arxiv.org/abs/1502.03167\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BatchNorm2d\n",
      " |      _BatchNorm\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from _BatchNorm:\n",
      " |  \n",
      " |  __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self)\n",
      " |  \n",
      " |  reset_running_stats(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |                  print(m)\n",
      " |                  if type(m) == nn.Linear:\n",
      " |                      m.weight.data.fill_(1.0)\n",
      " |                      print(m.weight)\n",
      " |      \n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, memo=None, prefix='')\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device)\n",
      " |      \n",
      " |      .. function:: to(dtype)\n",
      " |      \n",
      " |      .. function:: to(device, dtype)\n",
      " |      \n",
      " |      It has similar signature as :meth:`torch.Tensor.to`, but does not take\n",
      " |      a Tensor and only takes in floating point :attr:`dtype` s. In\n",
      " |      particular, this method will only cast the floating point parameters and\n",
      " |      buffers to :attr:`dtype`. It will still move the integral parameters and\n",
      " |      buffers to :attr:`device`, if that is given. See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.BatchNorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textCNN(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(textCNN, self).__init__()\n",
    "        vocb_size = args['vocb_size']\n",
    "        dim = args['dim']\n",
    "        n_class = args['n_class']\n",
    "        max_len = args['max_len']\n",
    "        embedding_matrix=args['embedding_matrix']\n",
    "        # 需要将事先训练好的词向量载入\n",
    "        self.embeding = nn.Embedding(vocb_size, dim,_weight=embedding_matrix)\n",
    "        self.conv1 = nn.Sequential(\n",
    "                     nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5,\n",
    "                               stride=1, padding=2),\n",
    " \n",
    "                     nn.ReLU(),\n",
    "                     nn.MaxPool2d(kernel_size=2) # (16,64,64)\n",
    "                     )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                     nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "                     nn.ReLU(),\n",
    "                     nn.MaxPool2d(2)\n",
    "                     )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(  # (16,64,64)\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.out = nn.Linear(512, n_class)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.embeding(x)\n",
    "        x=x.view(x.size(0),1,max_len,word_dim)\n",
    "        # print(x.size())\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1) # 将（batch，outchanel,w,h）展平为（batch，outchanel*w*h）\n",
    "        # print(x.size())\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "#损失函数\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#训练批次大小\n",
    "epoch_size=1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for i in range(0,(int)(len(train_x)/epoch_size)):\n",
    " \n",
    "        b_x = Variable(torch.LongTensor(train_x[i*epoch_size:i*epoch_size+epoch_size]))\n",
    " \n",
    "        b_y = Variable(torch.LongTensor((train_y[i*epoch_size:i*epoch_size+epoch_size])))\n",
    "        output = cnn(b_x)\n",
    "        loss = loss_function(output, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(str(i))\n",
    "        print(loss)\n",
    "        pred_y = torch.max(output, 1)[1].data.squeeze()\n",
    "        acc = (b_y == pred_y)\n",
    "        acc = acc.numpy().sum()\n",
    "        accuracy = acc / (b_y.size(0))\n",
    " \n",
    "    acc_all = 0;\n",
    "    for j in range(0, (int)(len(test_x) / test_epoch_size)):\n",
    "        b_x = Variable(torch.LongTensor(test_x[j * test_epoch_size:j * test_epoch_size + test_epoch_size]))\n",
    "        b_y = Variable(torch.LongTensor((test_y[j * test_epoch_size:j * test_epoch_size + test_epoch_size])))\n",
    "        test_output = cnn(b_x)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "        # print(pred_y)\n",
    "        # print(test_y)\n",
    "        acc = (pred_y == b_y)\n",
    "        acc = acc.numpy().sum()\n",
    "        print(\"acc \" + str(acc / b_y.size(0)))\n",
    "        acc_all = acc_all + acc\n",
    " \n",
    "    accuracy = acc_all / (test_y.size(0))\n",
    "    print(\"epoch \" + str(epoch) + \" step \" + str(i) + \" \" + \"acc \" + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
